{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent Surveys\n",
    "\n",
    "This notebook evaluates the most recent surveys and is a benchmark to see how good we can predict consumption using the public available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import estimator_util as eu\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df, all_cols = eu.get_data(\"../data/lsms/processed/_all_real.csv\", \"../data/cnn_features/resnet_trans_all_countries_hyper_ncomp_5.csv\", \"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1, random_state=1)\n",
    "_ = pca.fit(complete_df[all_cols])\n",
    "features_weights = list(zip(all_cols, pca.components_.T))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict r^2 for every country in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_osm(complete):\n",
    "    countries = [\"NG\", \"ETH\" ,\"TZA\", \"MW\"]\n",
    "    for i, country in enumerate(countries):\n",
    "        tmp_df = complete.loc[complete.country == country]\n",
    "        years = tmp_df.groupby([\"year\"]).groups.keys()\n",
    "        year = max(years)\n",
    "        X, y = eu.get_recent_features(tmp_df, [country], all_cols)\n",
    "        r2, y_hest, model = eu.run_ridge(X, y, alpha=1000, seed=1)\n",
    "        fig = eu.plot_predictions(y, y_hest, r2, country, year, i)\n",
    "        fig.savefig(f\"../figs/{country}_{year}_cnnosm.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_osm(complete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rural vs. Urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rural_urban(complete):    \n",
    "    types = [\"rural\", \"urban\"]\n",
    "    types_r2 = {}\n",
    "    rural = []\n",
    "    ys = []\n",
    "    y_preds = []\n",
    "    # get features\n",
    "    for type in types:    \n",
    "        r2s = []\n",
    "        countries = [\"NG\", \"ETH\" ,\"TZA\", \"MW\"]\n",
    "        X = None\n",
    "        y = None\n",
    "        for i, country in enumerate(countries):\n",
    "            tmp_df = complete.loc[complete.country == country]\n",
    "            years = tmp_df.groupby([\"year\"]).groups.keys()\n",
    "            year = max(years)\n",
    "            year_df = tmp_df.loc[tmp_df.year == year]\n",
    "            year_df = year_df.loc[year_df.rural == type]\n",
    "            rural += year_df.rural.values.tolist()\n",
    "            cnn_X = np.array([np.array(x) for x in year_df[\"features\"].values])\n",
    "            osm_X = year_df[all_cols].values\n",
    "            tmp_X = np.hstack((cnn_X, osm_X))\n",
    "            y_ = year_df[\"cons_pc\"].values\n",
    "\n",
    "            if X is None:\n",
    "                X = tmp_X\n",
    "            else:\n",
    "                X = np.vstack((X, tmp_X))\n",
    "            if y is None:\n",
    "                y = y_\n",
    "            else:\n",
    "                y = np.append(y, y_)\n",
    "\n",
    "        y = np.log(y)\n",
    "        ys += y.tolist()\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X = scaler.transform(X)\n",
    "        r, y_hest, _ = eu.run_ridge(X, y, alpha=1000)\n",
    "        y_preds += y_hest.tolist()\n",
    "        r2s.append(r)\n",
    "        types_r2[type] = r2s\n",
    "\n",
    "    # for the plot\n",
    "    plt_df = pd.DataFrame.from_dict({\"y\": ys, \"y_pred\": y_preds, \"rural\": rural})\n",
    "\n",
    "    x_col = \"y\"\n",
    "    y_col = \"y_pred\"\n",
    "    hue_col = \"rural\"\n",
    "\n",
    "    penguins = plt_df\n",
    "    g = sns.jointplot(data=penguins, x=x_col, y=y_col, hue=hue_col)\n",
    "    \n",
    "    for _, gr in penguins.groupby(hue_col):\n",
    "        sns.regplot(x=x_col, y=y_col, data=gr, scatter=False, ax=g.ax_joint, truncate=False)\n",
    "    print(types_r2)\n",
    "    g.ax_joint.set_xlabel(\"Observed nominal consumption($/day)\")\n",
    "    g.ax_joint.set_ylabel(\"Predicted nominal consumption($/day)\")\n",
    "    plt.text(-0.8, 1, fr\"$r^2 = {round(types_r2['rural'][0], 2)}$\", c=\"#4c72b0\")\n",
    "    plt.text(-0.8, 0.8, fr\"$r^2 = {round(types_r2['urban'][0], 2)}$\", c=\"#dd8452\")\n",
    "    plt.legend([],[], frameon=False)\n",
    "    g.ax_joint.get_legend().remove()\n",
    "    g.ax_joint.text(-0.1, 1.1, string.ascii_uppercase[0], size=20, weight='bold', transform=g.ax_joint.transAxes)\n",
    "    plt.savefig(\"../figs/rural_urban_pop.pdf\", dpi=600, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_urban(complete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict % of poorest people in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled_features_perc(complete):   \n",
    "    features = [\"CNN\", \"OSM\", \"CNN+OSM\"]\n",
    "    feature_r2 = {}\n",
    "    for feature in features:    \n",
    "        r2s = []\n",
    "        for i in tqdm(np.linspace(0.1,1,91)):\n",
    "            perc_df = complete.loc[complete.cons_pc <= complete.cons_pc.quantile(i)]\n",
    "            countries = [\"NG\", \"ETH\" ,\"TZA\", \"MW\"]\n",
    "            X = None\n",
    "            y = None\n",
    "            for i, country in enumerate(countries):\n",
    "                tmp_df = perc_df.loc[perc_df.country == country]\n",
    "                years = tmp_df.groupby([\"year\"]).groups.keys()\n",
    "                year = max(years)\n",
    "                year_df = tmp_df.loc[tmp_df.year == year]\n",
    "                if feature == \"CNN\":\n",
    "                    tmp_X = np.array([np.array(x) for x in year_df[\"features\"].values])\n",
    "                elif feature == \"OSM\":\n",
    "                    tmp_X = year_df[all_cols].values\n",
    "                else:\n",
    "                    cnn_X = np.array([np.array(x) for x in year_df[\"features\"].values])\n",
    "                    osm_X = year_df[all_cols].values\n",
    "                    tmp_X = np.hstack((cnn_X, osm_X))\n",
    "                    \n",
    "                y_ = year_df[\"cons_pc\"].values\n",
    "\n",
    "                if X is None:\n",
    "                    X = tmp_X\n",
    "                else:\n",
    "                    X = np.vstack((X, tmp_X))\n",
    "                \n",
    "                if y is None:\n",
    "                    y = y_\n",
    "                else:\n",
    "                    y = np.append(y, y_)\n",
    "\n",
    "            y = np.log(y)\n",
    "            scaler = StandardScaler().fit(X)\n",
    "            X = scaler.transform(X)\n",
    "            r, _, _ = eu.run_ridge(X, y, alpha=1000)\n",
    "            r2s.append(r)\n",
    "        feature_r2[feature] = r2s\n",
    "    \n",
    "    colors = [\"#2a9d8f\", \"#e9c46a\", \"#e76f51\"]\n",
    "    for i, feature in enumerate(feature_r2):\n",
    "        plt.plot(np.linspace(0.1,1,91)*100, feature_r2[feature], c=colors[i], label=feature)\n",
    "    \n",
    "    plt.xlabel(\"Poorest percent of cluster used\")\n",
    "    plt.ylabel(r\"$r^2$\")\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    ax.text(-0.1, 1.1, string.ascii_uppercase[1], size=20, weight='bold', transform=ax.transAxes)\n",
    "    plt.savefig(\"../figs/pooled_percentile.pdf\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_features_perc(complete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting performance from each feature alone and combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_features_performance(complete):   \n",
    "    features = [\"CNN\", \"OSM\", \"CNN+OSM\"]\n",
    "    feature_r2 = {}\n",
    "    for feature in features:    \n",
    "        r2s = []        \n",
    "        countries = [\"NG\", \"ETH\" ,\"TZA\", \"MW\"]\n",
    "        X = None\n",
    "        y = None\n",
    "        for i, country in enumerate(countries):\n",
    "            tmp_df = complete.loc[complete.country == country]\n",
    "            years = tmp_df.groupby([\"year\"]).groups.keys()\n",
    "            year = max(years)\n",
    "            year_df = tmp_df.loc[tmp_df.year == year]\n",
    "            if feature == \"CNN\":\n",
    "                tmp_X = np.array([np.array(x) for x in year_df[\"features\"].values])\n",
    "                tmp_X = StandardScaler().fit_transform(tmp_X)\n",
    "            elif feature == \"OSM\":\n",
    "                tmp_X = year_df[all_cols].values\n",
    "            else:\n",
    "                cnn_X = np.array([np.array(x) for x in year_df[\"features\"].values])\n",
    "                osm_X = year_df[all_cols].values\n",
    "                tmp_X = np.hstack((cnn_X, osm_X))\n",
    "                \n",
    "            y = year_df[\"cons_pc\"].values\n",
    "\n",
    "            X = tmp_X\n",
    "           \n",
    "            y = np.log(y)\n",
    "            scaler = StandardScaler().fit(X)\n",
    "            X = scaler.transform(X)\n",
    "            r, _, _ = eu.run_ridge(X, y, alpha=1000)\n",
    "            r2s.append(r)\n",
    "            feature_r2[feature] = r2s\n",
    "            \n",
    "    feat_df = pd.DataFrame.from_dict(feature_r2)\n",
    "    feat_df[\"country\"] = countries\n",
    "    return feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_features_performance(complete_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
