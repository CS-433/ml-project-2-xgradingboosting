{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent Surveys\n",
    "\n",
    "This notebook evaluates the most recent surveys and is a benchmark to see how good we can predict consumption using the public available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sallinen/Programmation/predicting-poverty-through-time/src\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sallinen/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from lib import estimator_util as eu\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df, all_cols = eu.get_data(\"../data/lsms/processed/_all_real.csv\", \"../data/cnn_features/resnet_trans_all_countries_hyper.csv\", \"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1, random_state=1)\n",
    "_ = pca.fit(complete_df[all_cols])\n",
    "features_weights = list(zip(all_cols, pca.components_.T))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get names of useless OSM features for the 4 countries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "countries = [\"NG\", \"ETH\" ,\"TZA\", \"MW\"]\n",
    "X, _, _, _ = eu.get_recent_osm_features(complete_df, countries, all_cols)\n",
    "X = pd.DataFrame(X, columns=all_cols)\n",
    "null_features = X.loc[:, (X == 0).any(axis=0)].keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict r^2 for every country in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_osm(complete, model_, params = None):\n",
    "    countries = [\"NG\", \"ETH\" ,\"TZA\", \"MW\"]\n",
    "    all_trained_models = []\n",
    "    for i, country in enumerate(countries):\n",
    "        tmp_df = complete.loc[complete.country == country]\n",
    "        years = tmp_df.groupby([\"year\"]).groups.keys()\n",
    "        year = max(years)\n",
    "        X, y = eu.get_recent_features(tmp_df, [country], all_cols)\n",
    "        r2, y_real, y_predicted, trained_model = eu.run_model(X, y, model_, seed=1, **(params[i]))\n",
    "        fig = eu.plot_predictions(y_real, y_predicted, r2, country, year, i)\n",
    "        fig.savefig(f\"../figs/{country}_{year}_cnnosm_{model_}.pdf\", dpi=600)\n",
    "        all_trained_models.append(trained_model)\n",
    "    return all_trained_models\n",
    "\n",
    "def cnn_osm2(complete, model_, country, **params):\n",
    "    tmp_df = complete.loc[complete.country == country]\n",
    "    years = tmp_df.groupby([\"year\"]).groups.keys()\n",
    "    year = max(years)\n",
    "    X, y = eu.get_recent_features(tmp_df, [country], all_cols, null_osm_features=null_features)\n",
    "    r2, y_real, y_predicted, trained_model = eu.run_model(X, y, model_, seed=1, **params)\n",
    "    fig = eu.plot_predictions(y_real, y_predicted, r2, country, year)\n",
    "    fig.savefig(f\"../figs/{country}_{year}_cnnosm_{model_.__name__}.pdf\", dpi=600)\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_osm(complete_df, Ridge, [{'alpha' : 1000}]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    cnn_osm2(complete_df, Ridge, country, alpha = 1000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    cnn_osm2(complete_df, XGBRegressor, country)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5107 is out of bounds for axis 0 with size 651",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 30\u001B[0m\n\u001B[1;32m     25\u001B[0m             best_params[country]\u001B[38;5;241m.\u001B[39mupdate({key : result\u001B[38;5;241m.\u001B[39mbest_params_[key]})\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m best_params\n\u001B[0;32m---> 30\u001B[0m best_params \u001B[38;5;241m=\u001B[39m \u001B[43moptimize_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcomplete_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mRidge\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43malpha\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinspace\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m max_depth \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m4\u001B[39m]\n\u001B[1;32m     32\u001B[0m n_estimators \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m50\u001B[39m,\u001B[38;5;241m100\u001B[39m]\n",
      "Cell \u001B[0;32mIn[23], line 17\u001B[0m, in \u001B[0;36moptimize_params\u001B[0;34m(complete, model_, params, seed, doPlot)\u001B[0m\n\u001B[1;32m     15\u001B[0m X, y \u001B[38;5;241m=\u001B[39m eu\u001B[38;5;241m.\u001B[39mget_recent_features(tmp_df, [country], all_cols)\n\u001B[1;32m     16\u001B[0m search \u001B[38;5;241m=\u001B[39m GridSearchCV(model_, param_grid\u001B[38;5;241m=\u001B[39mparams, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr2\u001B[39m\u001B[38;5;124m'\u001B[39m, cv\u001B[38;5;241m=\u001B[39mkf)\n\u001B[0;32m---> 17\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43msearch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m params:\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m doPlot:\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    871\u001B[0m     )\n\u001B[1;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1379\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1379\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    819\u001B[0m         )\n\u001B[1;32m    820\u001B[0m     )\n\u001B[0;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    843\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    844\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/joblib/parallel.py:1048\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1040\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[1;32m   1041\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1045\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[1;32m   1046\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[1;32m   1047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1048\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1049\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1051\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/joblib/parallel.py:864\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    863\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 864\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    865\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/joblib/parallel.py:782\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    780\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    781\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 782\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/joblib/parallel.py:263\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    264\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/joblib/parallel.py:263\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    264\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[0;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:678\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    674\u001B[0m     estimator \u001B[38;5;241m=\u001B[39m estimator\u001B[38;5;241m.\u001B[39mset_params(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcloned_parameters)\n\u001B[1;32m    676\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 678\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m \u001B[43m_safe_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    679\u001B[0m X_test, y_test \u001B[38;5;241m=\u001B[39m _safe_split(estimator, X, y, test, train)\n\u001B[1;32m    681\u001B[0m result \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/sklearn/utils/metaestimators.py:308\u001B[0m, in \u001B[0;36m_safe_split\u001B[0;34m(estimator, X, y, indices, train_indices)\u001B[0m\n\u001B[1;32m    306\u001B[0m         X_subset \u001B[38;5;241m=\u001B[39m X[np\u001B[38;5;241m.\u001B[39mix_(indices, train_indices)]\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 308\u001B[0m     X_subset \u001B[38;5;241m=\u001B[39m \u001B[43m_safe_indexing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    311\u001B[0m     y_subset \u001B[38;5;241m=\u001B[39m _safe_indexing(y, indices)\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/sklearn/utils/__init__.py:361\u001B[0m, in \u001B[0;36m_safe_indexing\u001B[0;34m(X, indices, axis)\u001B[0m\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001B[38;5;241m=\u001B[39maxis)\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 361\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_array_indexing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    363\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001B[0;32m~/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/sklearn/utils/__init__.py:185\u001B[0m, in \u001B[0;36m_array_indexing\u001B[0;34m(array, key, key_dtype, axis)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    184\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m--> 185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marray\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m array[:, key]\n",
      "\u001B[0;31mIndexError\u001B[0m: index 5107 is out of bounds for axis 0 with size 651"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "def optimize_params(complete, model_, params, seed, doPlot=False):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "    countries = [\"NG\", \"ETH\", \"TZA\", \"MW\"]\n",
    "    best_params = {\"NG\":{}, \"ETH\": {}, \"TZA\": {}, \"MW\": {}}\n",
    "    for country in tqdm(countries):\n",
    "        tmp_df = complete.loc[complete.country == country]\n",
    "        years = tmp_df.groupby([\"year\"]).groups.keys()\n",
    "        year = max(years)\n",
    "        X, y = eu.get_recent_features(tmp_df, [country], all_cols)\n",
    "        search = GridSearchCV(model_, param_grid=params, scoring='r2', cv=kf)\n",
    "        result = search.fit(X, y)\n",
    "        for key in params:\n",
    "            if doPlot:\n",
    "                plt.plot(params[key], result.cv_results_['mean_test_score'], label=country)\n",
    "                plt.xlabel(key)\n",
    "                plt.ylabel('r2')\n",
    "                plt.legend()\n",
    "\n",
    "            best_params[country].update({key : result.best_params_[key]})\n",
    "\n",
    "    return best_params\n",
    "\n",
    "\n",
    "best_params = optimize_params(complete_df, Ridge(), params={'alpha': np.linspace(500, 5000, num=100)}, seed=1)\n",
    "max_depth = [2,4]\n",
    "n_estimators = [50,100]\n",
    "#best_params = optimize_params(complete_df, XGBRegressor(), params={'max_depth': max_depth, 'n_estimators': n_estimators}, seed=1)\n",
    "\n",
    "print(best_params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, country in enumerate(countries):\n",
    "    cnn_osm2(complete_df, Ridge, country, alpha = best_params[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_scores, best_params = optimize_params(complete_df, CatBoostRegressor(), params={'max_depth': max_depth, 'n_estimators': n_estimators}, seed=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = cnn_osm(complete_df, XGBRegressor, best_params)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for country in tqdm(countries):\n",
    "    cnn_osm2(complete_df, CatBoostRegressor, country, task_type=\"GPU\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rural vs. Urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rural_urban(complete):    \n",
    "    types = [\"rural\", \"urban\"]\n",
    "    types_r2 = {}\n",
    "    rural = []\n",
    "    ys = []\n",
    "    y_preds = []\n",
    "    # get features\n",
    "    for type in types:    \n",
    "        r2s = []\n",
    "        countries = [\"NG\", \"ETH\" ,\"TZA\", \"MW\"]\n",
    "        X = None\n",
    "        y = None\n",
    "        for i, country in enumerate(countries):\n",
    "            tmp_df = complete.loc[complete.country == country]\n",
    "            years = tmp_df.groupby([\"year\"]).groups.keys()\n",
    "            year = max(years)\n",
    "            year_df = tmp_df.loc[tmp_df.year == year]\n",
    "            year_df = year_df.loc[year_df.rural == type]\n",
    "            rural += year_df.rural.values.tolist()\n",
    "            cnn_X = np.array([np.array(x) for x in year_df[\"features\"].values])\n",
    "            osm_X = year_df[all_cols].values\n",
    "            tmp_X = np.hstack((cnn_X, osm_X))\n",
    "            y_ = year_df[\"cons_pc\"].values\n",
    "\n",
    "            if X is None:\n",
    "                X = tmp_X\n",
    "            else:\n",
    "                X = np.vstack((X, tmp_X))\n",
    "            if y is None:\n",
    "                y = y_\n",
    "            else:\n",
    "                y = np.append(y, y_)\n",
    "\n",
    "        y = np.log(y)\n",
    "        ys += y.tolist()\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X = scaler.transform(X)\n",
    "        r, y_hest, _ = eu.run_ridge(X, y, alpha=1000)\n",
    "        y_preds += y_hest.tolist()\n",
    "        r2s.append(r)\n",
    "        types_r2[type] = r2s\n",
    "\n",
    "    # for the plot\n",
    "    plt_df = pd.DataFrame.from_dict({\"y\": ys, \"y_pred\": y_preds, \"rural\": rural})\n",
    "\n",
    "    x_col = \"y\"\n",
    "    y_col = \"y_pred\"\n",
    "    hue_col = \"rural\"\n",
    "\n",
    "    penguins = plt_df\n",
    "    g = sns.jointplot(data=penguins, x=x_col, y=y_col, hue=hue_col)\n",
    "    \n",
    "    for _, gr in penguins.groupby(hue_col):\n",
    "        sns.regplot(x=x_col, y=y_col, data=gr, scatter=False, ax=g.ax_joint, truncate=False)\n",
    "    print(types_r2)\n",
    "    g.ax_joint.set_xlabel(\"Observed nominal consumption($/day)\")\n",
    "    g.ax_joint.set_ylabel(\"Predicted nominal consumption($/day)\")\n",
    "    plt.text(-0.8, 1, fr\"$r^2 = {round(types_r2['rural'][0], 2)}$\", c=\"#4c72b0\")\n",
    "    plt.text(-0.8, 0.8, fr\"$r^2 = {round(types_r2['urban'][0], 2)}$\", c=\"#dd8452\")\n",
    "    plt.legend([],[], frameon=False)\n",
    "    g.ax_joint.get_legend().remove()\n",
    "    g.ax_joint.text(-0.1, 1.1, string.ascii_uppercase[0], size=20, weight='bold', transform=g.ax_joint.transAxes)\n",
    "    plt.savefig(\"../figs/rural_urban_pop.pdf\", dpi=600, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_urban(complete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict % of poorest people in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled_features_perc(complete):   \n",
    "    features = [\"CNN\", \"OSM\", \"CNN+OSM\"]\n",
    "    feature_r2 = {}\n",
    "    for feature in features:    \n",
    "        r2s = []\n",
    "        for i in tqdm(np.linspace(0.1,1,91)):\n",
    "            perc_df = complete.loc[complete.cons_pc <= complete.cons_pc.quantile(i)]\n",
    "            countries = [\"NG\", \"ETH\" ,\"TZA\", \"MW\"]\n",
    "            X = None\n",
    "            y = None\n",
    "            for i, country in enumerate(countries):\n",
    "                tmp_df = perc_df.loc[perc_df.country == country]\n",
    "                years = tmp_df.groupby([\"year\"]).groups.keys()\n",
    "                year = max(years)\n",
    "                year_df = tmp_df.loc[tmp_df.year == year]\n",
    "                if feature == \"CNN\":\n",
    "                    tmp_X = np.array([np.array(x) for x in year_df[\"features\"].values])\n",
    "                elif feature == \"OSM\":\n",
    "                    tmp_X = year_df[all_cols].values\n",
    "                else:\n",
    "                    cnn_X = np.array([np.array(x) for x in year_df[\"features\"].values])\n",
    "                    osm_X = year_df[all_cols].values\n",
    "                    tmp_X = np.hstack((cnn_X, osm_X))\n",
    "                    \n",
    "                y_ = year_df[\"cons_pc\"].values\n",
    "\n",
    "                if X is None:\n",
    "                    X = tmp_X\n",
    "                else:\n",
    "                    X = np.vstack((X, tmp_X))\n",
    "                \n",
    "                if y is None:\n",
    "                    y = y_\n",
    "                else:\n",
    "                    y = np.append(y, y_)\n",
    "\n",
    "            y = np.log(y)\n",
    "            scaler = StandardScaler().fit(X)\n",
    "            X = scaler.transform(X)\n",
    "            r, _, _ = eu.run_ridge(X, y, alpha=1000)\n",
    "            r2s.append(r)\n",
    "        feature_r2[feature] = r2s\n",
    "    \n",
    "    colors = [\"#2a9d8f\", \"#e9c46a\", \"#e76f51\"]\n",
    "    for i, feature in enumerate(feature_r2):\n",
    "        plt.plot(np.linspace(0.1,1,91)*100, feature_r2[feature], c=colors[i], label=feature)\n",
    "    \n",
    "    plt.xlabel(\"Poorest percent of cluster used\")\n",
    "    plt.ylabel(r\"$r^2$\")\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    ax.text(-0.1, 1.1, string.ascii_uppercase[1], size=20, weight='bold', transform=ax.transAxes)\n",
    "    plt.savefig(\"../figs/pooled_percentile.pdf\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_features_perc(complete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting performance from each feature alone and combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_features_performance(complete):   \n",
    "    features = [\"CNN\", \"OSM\", \"CNN+OSM\"]\n",
    "    feature_r2 = {}\n",
    "    for feature in features:    \n",
    "        r2s = []        \n",
    "        countries = [\"NG\", \"ETH\" ,\"TZA\", \"MW\"]\n",
    "        X = None\n",
    "        y = None\n",
    "        for i, country in enumerate(countries):\n",
    "            tmp_df = complete.loc[complete.country == country]\n",
    "            years = tmp_df.groupby([\"year\"]).groups.keys()\n",
    "            year = max(years)\n",
    "            year_df = tmp_df.loc[tmp_df.year == year]\n",
    "            if feature == \"CNN\":\n",
    "                tmp_X = np.array([np.array(x) for x in year_df[\"features\"].values])\n",
    "                tmp_X = StandardScaler().fit_transform(tmp_X)\n",
    "            elif feature == \"OSM\":\n",
    "                tmp_X = year_df[all_cols].values\n",
    "            else:\n",
    "                cnn_X = np.array([np.array(x) for x in year_df[\"features\"].values])\n",
    "                osm_X = year_df[all_cols].values\n",
    "                tmp_X = np.hstack((cnn_X, osm_X))\n",
    "                \n",
    "            y = year_df[\"cons_pc\"].values\n",
    "\n",
    "            X = tmp_X\n",
    "           \n",
    "            y = np.log(y)\n",
    "            scaler = StandardScaler().fit(X)\n",
    "            X = scaler.transform(X)\n",
    "            r, _, _ = eu.run_ridge(X, y, alpha=1000)\n",
    "            r2s.append(r)\n",
    "            feature_r2[feature] = r2s\n",
    "            \n",
    "    feat_df = pd.DataFrame.from_dict(feature_r2)\n",
    "    feat_df[\"country\"] = countries\n",
    "    return feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_features_performance(complete_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
