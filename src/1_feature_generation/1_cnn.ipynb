{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperspectral CNN\n",
    "\n",
    "This code is to train the Hyperspectral CNN. Warning: You need at least 18GB of RAM, to process the TfRecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sallinen/Programmation/predicting-poverty-through-time/src\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from lib.tfrecordhelper import TfrecordHelper\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#added for reproducibility\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path: str):\n",
    "    \"\"\"\n",
    "    Helper to load dataset\n",
    "\n",
    "    Args:\n",
    "    - path (str): Path to dataset\n",
    "\n",
    "    Returns:\n",
    "    - dic which contains all data\n",
    "    \"\"\"\n",
    "    tf_helper = TfrecordHelper(path, ls_bands=\"ms\", nl_band=\"viirs\")\n",
    "    input_dic = {}\n",
    "    tf_helper.keyword_lat = \"lat\"\n",
    "    tf_helper.keyword_lon = \"lon\"\n",
    "    tf_helper.process_dataset()\n",
    "    for i, feature in enumerate(tf_helper.dataset):\n",
    "        input_dic[i] = {\n",
    "        \"year\": feature[\"years\"].numpy(),\n",
    "        \"cluster_lat\": feature[\"locs\"].numpy()[0],\n",
    "        \"cluster_lon\": feature[\"locs\"].numpy()[1],\n",
    "        \"img\": (feature[\"images\"][:,:,:7].numpy()),\n",
    "        \"nightlight\": np.mean(feature[\"images\"][:,:,7].numpy()),\n",
    "    }\n",
    "    \n",
    "    # Remove data where entry is broken (one channel contains only zeros)\n",
    "    remove = []\n",
    "    for feature in tqdm(input_dic):\n",
    "        if input_dic[feature][\"nightlight\"] == 0:\n",
    "            remove.append(feature)\n",
    "            continue\n",
    "        for dim in input_dic[feature][\"img\"]:\n",
    "            if not np.any(dim):\n",
    "                remove.append(feature)\n",
    "                break\n",
    "    \n",
    "    for r in remove:\n",
    "        input_dic.pop(r)\n",
    "    return input_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/tfrecords/raw/\"\n",
    "files = os.listdir(path) # path to the processed tfrecords from the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 22:17:58.861771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-21 22:17:58.862655: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/781 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b7c59fd39484c52aa9203172f3c7505"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/669 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96328aa06a424f00931c3a0345e3d5b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/419 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96fcfd327c8a4262925b24a136176ac3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/503 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a43acba0498488f9b856bd81867f35d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/475 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a3662ce803c4f468c3d46c0ed619909"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/645 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3f417025d66423cb85ca17c7ae3fb81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1611 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64131fa21ed14e55881d56e0c0e7dcee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/710 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b4c29605bc74d23b2cd8818a47f36ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/516 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c25df8d9a1f4e71b59ed0e732754f1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/525 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58cef25eebc7456c8d0e5d39b574e1bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dics = [] # will contain all information\n",
    "for file in files:\n",
    "    raw_path = path + file\n",
    "    data = load_dataset(raw_path)\n",
    "    input_dics.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca61e5610a064adaa8a3eaef17f15c60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "years = []\n",
    "lat = []\n",
    "lon = []\n",
    "for country in tqdm(input_dics):\n",
    "    data = country\n",
    "    for feature in data:\n",
    "        years.append(data[feature][\"year\"])\n",
    "        lat.append(data[feature][\"cluster_lat\"])\n",
    "        lon.append(data[feature][\"cluster_lon\"])\n",
    "        data[feature][\"img\"][:3,:,:] *=3 # RGB images to dark, got better performance by using it\n",
    "        X.append(data[feature][\"img\"])\n",
    "        y.append(data[feature][\"nightlight\"])\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [np.mean(X[:,i,:,:]) for i in range(7)]\n",
    "stds = [np.std(X[:,i,:,:]) for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import lib.clusters_utils as cl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "cl.save_lat_lon(lat,lon)\n",
    "indices = cl.split_k_sets(2, lat=lat, lon=lon)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cl.plot_split_perf(indices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=means, std=stds)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bins for nighttime images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nightlights_to_class(data, model, n_components):\n",
    "    \"\"\"\n",
    "    Data are labels. Perform GMM based on the input and creates 5 classes out of it.\n",
    "\n",
    "    Args:\n",
    "    - data: radiance (nighttime images)\n",
    "\n",
    "    Return:\n",
    "    - list of labels\n",
    "    \"\"\"\n",
    "    x = data.reshape(-1,1)\n",
    "    model_ = model.fit(x)\n",
    "    labels = model_.predict(x)\n",
    "\n",
    "    if(model.converged_):\n",
    "        print(\"there is convergence in \")\n",
    "        print(model.n_iter_)\n",
    "    else :\n",
    "        print(\"no convergence\")\n",
    "    cutoffs = []\n",
    "    for i in range(n_components):\n",
    "        cutoffs.append(data[labels==i].max())\n",
    "    cutoffs = sorted(cutoffs)\n",
    "\n",
    "    y_labels = []\n",
    "\n",
    "    for d in data:\n",
    "        for i in range(n_components):\n",
    "            if d <= cutoffs[i]:\n",
    "                y_labels.append(i)\n",
    "                break\n",
    "\n",
    "    return np.array(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is convergence in \n",
      "10\n"
     ]
    }
   ],
   "source": [
    "n_components = 5\n",
    "#y_labels = nightlights_to_class(y,GMM(n_components=n_components, n_init=1, random_state=2), n_components=n_components) #0.562087\n",
    "#y_labels = nightlights_to_class(y,GMM(n_components=n_components, n_init=1, random_state=2, init_params='k-means++'), n_components=n_components) #0.549596\n",
    "#y_labels = nightlights_to_class(y,GMM(n_components=n_components, n_init=10, init_params='k-means++', random_state=2), n_components=n_components) #0.557678\n",
    "#y_labels = nightlights_to_class(y,GMM(n_components=n_components, n_init=10, random_state=2), n_components=n_components) #0.534166\n",
    "\n",
    "#y_labels = nightlights_to_class(y,GMM(n_components=n_components, n_init=1, random_state=1), n_components=n_components) #0.562454\n",
    "y_labels = nightlights_to_class(y,GMM(n_components=n_components, init_params='k-means++', random_state=1), n_components=n_components) #0.566495\n",
    "#y_labels = nightlights_to_class(y,GMM(n_components=n_components, n_init=10, init_params='k-means++', random_state=1), n_components=n_components) #0.547759\n",
    "#y_labels = nightlights_to_class(y,GMM(n_components=n_components, n_init=10, random_state=1), n_components=n_components) #0.562454"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = data\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x) # transpose is required by PyTorch\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(X, y_labels, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = list(range(len(dataset)))\n",
    "#split = int(np.floor(.4 * len(dataset)))\n",
    "train_indices, val_indices = indices[0], indices[1]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=128,\n",
    "                                                sampler=valid_sampler)\n",
    "dataloaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"val\": validation_loader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    \"train\": len(train_sampler),\n",
    "    \"val\": len(valid_sampler)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "3267"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_indices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/sallinen/.var/app/com.jetbrains.PyCharm-Professional/cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/sallinen/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sallinen/miniconda3/envs/predicting-poverty-through-time/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True) # load resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperspectral Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = nn.Conv2d(7, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), dilation=1, bias=False)\n",
    "model.conv1 = new_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = model\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc =  nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 100),\n",
    "    nn.Linear(100, 200),\n",
    "    nn.Linear(200, 5)\n",
    "    )\n",
    "# (Crop size) (Final layer NN)\n",
    "# (224x224) (100, 200, 200, 5) -> 0.570536\n",
    "# (224x224) (5)                -> 0.549963 / 0.562087\n",
    "\n",
    "# (255x255) (5)                -> 0.561352\n",
    "# (255x255) (100, 200, 200, 5) -> 0.540044\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/18\n",
      "----------\n",
      "train Loss: 1.2929 Acc: 0.4491\n",
      "val Loss: 1.0417 Acc: 0.4530\n",
      "\n",
      "Epoch 1/18\n",
      "----------\n",
      "train Loss: 1.0772 Acc: 0.5404\n",
      "val Loss: 1.0658 Acc: 0.4343\n",
      "\n",
      "Epoch 2/18\n",
      "----------\n",
      "train Loss: 1.0188 Acc: 0.5562\n",
      "val Loss: 1.0939 Acc: 0.4328\n",
      "\n",
      "Epoch 3/18\n",
      "----------\n",
      "train Loss: 0.9929 Acc: 0.5639\n",
      "val Loss: 1.4073 Acc: 0.4328\n",
      "\n",
      "Epoch 4/18\n",
      "----------\n",
      "train Loss: 0.9568 Acc: 0.5752\n",
      "val Loss: 1.4848 Acc: 0.4331\n",
      "\n",
      "Epoch 5/18\n",
      "----------\n",
      "train Loss: 0.9358 Acc: 0.5839\n",
      "val Loss: 1.4049 Acc: 0.4331\n",
      "\n",
      "Epoch 6/18\n",
      "----------\n",
      "train Loss: 0.9175 Acc: 0.5916\n",
      "val Loss: 1.7637 Acc: 0.4331\n",
      "\n",
      "Epoch 7/18\n",
      "----------\n",
      "train Loss: 0.8769 Acc: 0.6131\n",
      "val Loss: 1.1841 Acc: 0.4334\n",
      "\n",
      "Epoch 8/18\n",
      "----------\n",
      "train Loss: 0.8537 Acc: 0.6255\n",
      "val Loss: 1.6608 Acc: 0.4328\n",
      "\n",
      "Epoch 9/18\n",
      "----------\n",
      "train Loss: 0.8448 Acc: 0.6368\n",
      "val Loss: 1.3477 Acc: 0.4392\n",
      "\n",
      "Epoch 10/18\n",
      "----------\n",
      "train Loss: 0.8355 Acc: 0.6360\n",
      "val Loss: 1.7602 Acc: 0.4255\n",
      "\n",
      "Epoch 11/18\n",
      "----------\n",
      "train Loss: 0.8267 Acc: 0.6348\n",
      "val Loss: 1.9546 Acc: 0.4068\n",
      "\n",
      "Epoch 12/18\n",
      "----------\n",
      "train Loss: 0.8238 Acc: 0.6405\n",
      "val Loss: 1.0676 Acc: 0.4928\n",
      "\n",
      "Epoch 13/18\n",
      "----------\n",
      "train Loss: 0.8080 Acc: 0.6529\n",
      "val Loss: 1.5920 Acc: 0.4276\n",
      "\n",
      "Epoch 14/18\n",
      "----------\n",
      "train Loss: 0.8036 Acc: 0.6475\n",
      "val Loss: 1.0745 Acc: 0.5513\n",
      "\n",
      "Epoch 15/18\n",
      "----------\n",
      "train Loss: 0.8019 Acc: 0.6594\n",
      "val Loss: 1.0068 Acc: 0.4888\n",
      "\n",
      "Epoch 16/18\n",
      "----------\n",
      "train Loss: 0.7964 Acc: 0.6518\n",
      "val Loss: 1.0404 Acc: 0.5632\n",
      "\n",
      "Epoch 17/18\n",
      "----------\n",
      "train Loss: 0.7934 Acc: 0.6583\n",
      "val Loss: 1.2225 Acc: 0.5467\n",
      "\n",
      "Epoch 18/18\n",
      "----------\n",
      "train Loss: 0.7913 Acc: 0.6543\n",
      "val Loss: 1.8506 Acc: 0.4325\n",
      "\n",
      "Training complete in 3m 37s\n",
      "Best val Acc: 0.563208\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_ft"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'model_weights_all_countries_multichannel_{time.time()}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmodel = torch.nn.Sequential(*list(model_ft.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    nmodel.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/781 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e3a90f4d7c44f05a9b4e48669242568"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/669 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb5ec35e5237448893f234c51c72cceb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/419 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf2841f0a7cf4bbd9224b21f38a5cbd4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/479 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea81506f94cf4897b962d4ee168fb004"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/475 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a7ebc02e15441ff8afc9febdf3d32b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/645 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42ebee2436ca4d11b75a88ea4e50e96d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1588 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "183d79f8104047099048451317e0b7c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/708 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d787703ccca14ffbbe210e8bb30642d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/516 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11fc4921f0684308a1728ea36ff617e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/525 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07d6db04bc49422aa513bf7362c9250a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data in input_dics:\n",
    "    for feature in tqdm(data, total=len(data)):\n",
    "        input_batch = preprocess(data[feature]['img']).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = nmodel(input_batch.to('cuda'))\n",
    "        data[feature][\"feature\"] = np.squeeze(output.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge of weights and dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/781 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfbce0ccc32f4e88aebb1e43fd73bcb6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2075/3038713665.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(tmp)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/669 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20e4e7f375df44b387be26859dd786a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/419 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbf69ac91e4543779694a5bade377861"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/479 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cf58f740a904bdb89c7bca4ed355c46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2075/3038713665.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(tmp)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/475 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f9a8fc2670b43a6b1978071b7481f8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2075/3038713665.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(tmp)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/645 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44b3fdb588134354bf778096f5a1cd6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2075/3038713665.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(tmp)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1588 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa9a4093a93b41059a715bca60c5e899"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2075/3038713665.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(tmp)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/708 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a13adb7a99a745d682b1f1b26da2e13d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2075/3038713665.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(tmp)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/516 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8845bad745444a4db97b03c71e67293d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2075/3038713665.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(tmp)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/525 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62df23b3f1e3439e848bf180f475f05d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2075/3038713665.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(tmp)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for data in input_dics:\n",
    "    years = []\n",
    "    lat = []\n",
    "    lon = []\n",
    "    features = []\n",
    "    nightlights = []\n",
    "    for feature in tqdm(data, total=len(data)):\n",
    "        years.append(data[feature][\"year\"])\n",
    "        lat.append(data[feature][\"cluster_lat\"])\n",
    "        lon.append(data[feature][\"cluster_lon\"])\n",
    "        features.append(data[feature][\"feature\"].numpy().tolist())\n",
    "        nightlights.append(data[feature][\"nightlight\"])\n",
    "    tmp = pd.DataFrame.from_dict({\"year\": years, \"lat\": lat, 'lon': lon, \"features\": features, \"nightlight\": nightlights})\n",
    "    df = df.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/cnn_features/resnet_trans_all_countries_hyper.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
